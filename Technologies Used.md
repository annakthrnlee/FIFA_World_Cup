# Technologies Used.md

## Data Cleaning and Analysis

Each group member will be working with Python to clean/apply/and build our project. Depending on the group member's role, different dependencies will be used to complete the necessary tasks. Everyone will be working with Pandas to perform exploratory analysis. Each member will use Jupyter Notebooks to save their work and publish the results so everyone can apply and view the analysis. 

Resources:
- Python
- Pandas 
- Jupyter Notebook 
- CSV 

## Database Storage

The group's data will be stored using SQL. The member in charge of the database will work with SQLAlchemy to import the desired information into Postgres as well as upload the final machine learning model. 

Resources:
- SQL
- SQLAlchemy

## Machine Learning 

The machine learning model will be built using Jupyter Notebook. The necessary dependencies will be imported into the file such as TensorFlow to create the finalized product. The datasets will be uploaded into Jupyter efficiently using the cleaned CSV files and merged to create the final dataset that will be uploaded into the neural networking model that the member creates. 
The model is a supervised machine learning model because it deals with labeled data (categorical) which is a perfect fit for the sources we chose. Within a supervised learning model, there are two forms, regression, and classification. Our group is working with classification because classification algorithms can analyze continuous and categorical variables; Classification is best used to predict discrete outcomes and is used to identify the category of new observations based on training data. 

Resources:
- TensforFlow
- SkLearn 

## Dashboard

To create our interactive dashboard we will be working with Tableau because it's simple to use and easy to create fun and meaningful graphs to represent our findings. 

Resources:
- Tableau 
